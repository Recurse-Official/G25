{
  "backend/app.py": {
    "content": "from fastapi import FastAPI\nfrom fastapi.middleware.cors import CORSMiddleware\n\nfrom routes.authentication import router as auth_router\nfrom routes.repository import router as repo_router\nfrom routes.database import router as db_router\n\napp = FastAPI()\n\n# Configure CORS\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\napp.include_router(auth_router, prefix=\"/api/auth\", tags=[\"auth\"])\napp.include_router(repo_router, prefix=\"/api/repo\", tags=[\"repo\"])\napp.include_router(db_router, prefix=\"/api/db\", tags=[\"db\"])\n\n# Root endpoint\n@app.get(\"/\")\nasync def root():\n    return {\"message\": \"API is running\"}\n\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(\"app:app\", host=\"0.0.0.0\", port=8000, reload=True)\n",
    "file_type": "server"
  },
  "backend/models/data_models.py": {
    "content": "from pydantic import BaseModel\nfrom typing import Optional \nclass createDb(BaseModel):\n    name:str\n\nclass addRepo(BaseModel):\n    id: int\n    name: str\n    full_name: str\n    is_active: str\n    backend_path: Optional[str] = \"\"\n\nclass getDataRequest(BaseModel):\n    dbName: str\n    id: str\n\nclass getDataResponse(BaseModel):\n    id: str\n    name: str\n    full_name: str\n    is_active: str\n    backend_path: str\n\nclass RemoveRepo(BaseModel):\n    id: str\n\nclass ReadDocsRequest(BaseModel):\n    full_name: str\n    access_token: str",
    "file_type": "server"
  },
  "backend/routes/assistant.py": {
    "content": "",
    "file_type": "server"
  },
  "backend/routes/authentication.py": {
    "content": "from fastapi import APIRouter, HTTPException, Depends\nfrom fastapi.responses import RedirectResponse\nimport httpx\nfrom datetime import datetime, timedelta\nimport jwt\n\nfrom utils.auth import get_current_user\n\nimport os\nfrom dotenv import load_dotenv\nload_dotenv()\n\nrouter = APIRouter()\n\nGITHUB_CLIENT_ID = os.getenv(\"GITHUB_CLIENT_ID\")\nGITHUB_CLIENT_SECRET = os.getenv(\"GITHUB_CLIENT_SECRET\")\nGITHUB_REDIRECT_URI = os.getenv(\"GITHUB_REDIRECT_URI\")\nACCESS_TOKEN_EXPIRE_MINUTES = int(os.getenv(\"ACCESS_TOKEN_EXPIRE_MINUTES\"))\nJWT_SECRET_KEY = os.getenv(\"JWT_SECRET_KEY\")\nJWT_ALGORITHM = \"HS256\"\n\nprint(\n    GITHUB_CLIENT_ID,\n    GITHUB_CLIENT_SECRET,\n    GITHUB_REDIRECT_URI,\n    ACCESS_TOKEN_EXPIRE_MINUTES,\n    JWT_SECRET_KEY\n)\n\n@router.get(\"/access-token\")\nasync def get_access_token(code: str):\n    \"\"\"GitHub OAuth callback Handler\"\"\"\n\n\n    token_url = \"https://github.com/login/oauth/access_token\"\n    async with httpx.AsyncClient() as client:\n        response = await client.post(\n            token_url,\n            data={\n                \"client_id\": GITHUB_CLIENT_ID,\n                \"client_secret\": GITHUB_CLIENT_SECRET,\n                \"code\": code,\n            },\n            headers={\"Accept\": \"application/json\"},\n        )\n        token_data = response.json()\n        \n        if \"error\" in token_data:\n            raise HTTPException(status_code=400, detail=token_data[\"error\"])\n        \n        # Get user info\n        github_token = token_data[\"access_token\"]\n        user_response = await client.get(\n            \"https://api.github.com/user\",\n            headers={\n                \"Authorization\": f\"Bearer {github_token}\",\n                \"Accept\": \"application/json\",\n            },\n        )\n        user_data = user_response.json()\n\n        # Create session token\n        session_data = {\n            \"github_token\": github_token,\n            \"user_id\": user_data[\"id\"],\n            \"username\": user_data[\"login\"],\n            \"exp\": datetime.utcnow() + timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)\n        }\n        session_token = jwt.encode(\n            session_data,\n            JWT_SECRET_KEY,\n            algorithm=JWT_ALGORITHM\n        )\n        \n        return {\"access_token\": session_token, \"token_type\": \"bearer\"}\n    \n\n@router.get(\"/user-data\")\nasync def user_data(current_user: dict = Depends(get_current_user)):\n    \"\"\"Get user data\"\"\"\n    async with httpx.AsyncClient() as client:\n        response = await client.get(\n            \"https://api.github.com/user\",\n            headers={\n                \"Authorization\": f\"Bearer {current_user['github_token']}\",\n                \"Accept\": \"application/json\",\n            },\n        )\n        user_data = response.json()\n\n        return user_data",
    "file_type": "server"
  },
  "backend/routes/database.py": {
    "content": "from fastapi import APIRouter,HTTPException\nfrom models.data_models import createDb, addRepo, getDataRequest, getDataResponse, RemoveRepo\nimport sqlite3\nimport logging\nimport os\nfrom fastapi import Body\n\nrouter=APIRouter()\n\n@router.post(\"/create_database\")\ndef create_database(createDbRequest : createDb):\n    try:\n        # Use path joining for cross-platform compatibility\n        db_path = os.path.join(\"backend/database\", f\"{createDbRequest.name}.db\")\n        print(db_path)\n        # Check if the database already exists\n        if os.path.exists(db_path):\n            return {\"message\": \"Database already exists\"}\n\n        # Create the database\n        with sqlite3.connect(db_path) as db:\n            cursor = db.cursor()\n            cursor.execute(\n                \"CREATE TABLE repos (id TEXT PRIMARY KEY, name TEXT, full_name TEXT, is_active TEXT, backend_path TEXT)\"\n            )\n            db.commit()\n            logging.info(\"Database created\")\n            return {\"message\": \"Database created successfully\"}\n    except sqlite3.Error as e:\n        logging.error(f\"Database error: {e}\")\n        return {\"message\": f\"Database error: {str(e)}\"}\n\n@router.post(\"/add_repo\")\ndef add_user(addRepoRequest : addRepo):\n    try:\n        db_path = os.path.join(\"backend/database\", f\"repos.db\")\n        with sqlite3.connect(db_path) as db:\n            cursor=db.cursor()\n            cursor.execute(\"INSERT INTO repos (id, name, full_name, is_active, backend_path) VALUES (?,?,?,?,?)\",(addRepoRequest.id, addRepoRequest.name, addRepoRequest.full_name, addRepoRequest.is_active, addRepoRequest.backend_path))\n            db.commit()\n            logging.info(\"Repo added\")\n            return {\"Message\": \"Repo added successfully\"}\n        \n    except sqlite3.Error as e:\n        logging.error(f\"Database error: {e}\")\n        return {\"Message\": f\"Database error: {str(e)}\"}\n    \n    except Exception as e:\n        logging.error(f\"Unexpected error: {e}\")\n        return {\"Message\": f\"Unexpected error: {str(e)}\"}\n    \n@router.delete(\"/remove_repo\")\ndef remove_repo(id: str):\n    try:\n        db_path = os.path.join(\"backend/database\", \"repos.db\")\n        print(\"Delete Repo\", id)\n        with sqlite3.connect(db_path) as db:\n            cursor = db.cursor()\n            \n            # Check if repo exists before attempting deletion\n            cursor.execute(\"SELECT id FROM repos WHERE id = ?\", (id,))\n            if not cursor.fetchone():\n                return {\"Message\": \"Repository not found\"}\n            \n            cursor.execute(\"DELETE FROM repos WHERE id = ?\", (id,))\n            db.commit()\n            \n            if cursor.rowcount > 0:\n                logging.info(\"Repo removed\")\n                return {\"Message\": \"Repository removed successfully\"}\n            else:\n                return {\"Message\": \"No repository was removed\"}\n                \n    except sqlite3.Error as e:\n        logging.error(f\"Database error: {e}\")\n        return {\"Message\": f\"Database error: {str(e)}\"}\n    except Exception as e:\n        logging.error(f\"Unexpected error: {e}\")\n        return {\"Message\": f\"Unexpected error: {str(e)}\"}\n    \n@router.get(\"/get_data\")\ndef get_data(getdatarequest: getDataRequest):\n    try:\n        # Use path joining for cross-platform compatibility\n        db_path = os.path.join(\"backend/database\", \"repos.db\")\n\n        with sqlite3.connect(db_path) as db:\n            cursor = db.cursor()\n            # Use parameterized query to prevent SQL injection\n            cursor.execute(\"SELECT * FROM repos WHERE id = ?\", (getdatarequest.id,))\n            data = cursor.fetchone()\n\n            if not data:\n                return {\"message\": \"No data found\"}\n\n            return getDataResponse(\n                id=data[0],\n                name=data[1],\n                full_name=data[2],\n                is_active=data[3],\n                backend_path=data[4],\n            )\n\n    except sqlite3.Error as e:\n        logging.error(f\"Database error: {e}\")\n        return {\"message\": f\"Database error: {str(e)}\"}\n    except Exception as e:\n        logging.error(f\"Unexpected error: {e}\")\n        return {\"message\": f\"Unexpected error: {str(e)}\"}\n",
    "file_type": "server"
  },
  "backend/routes/repository.py": {
    "content": "from fastapi import APIRouter, Depends, HTTPException\nfrom typing import List, Optional\nimport httpx\nimport sqlite3\nimport logging\nimport os\nfrom pydantic import BaseModel\nfrom utils.auth import get_current_user\nfrom models.data_models import ReadDocsRequest\nimport yaml\nimport jwt\n\nrouter = APIRouter()\n\nclass Repository(BaseModel):\n    id: int\n    name: str\n    full_name: str\n    is_active: bool = False\n    backend_path: Optional[str] = None\n\nclass RepoActivation(BaseModel):\n    backend_path: str\n\n@router.get(\"/list\")\nasync def list_repositories(current_user: dict = Depends(get_current_user)):\n    \"\"\"List all repositories the user has access to with their database status\"\"\"\n    async with httpx.AsyncClient() as client:\n        response = await client.get(\n            \"https://api.github.com/user/repos\",\n            headers={\n                \"Authorization\": f\"Bearer {current_user['github_token']}\",\n                \"Accept\": \"application/json\",\n            },\n        )\n        \n        if response.status_code != 200:\n            raise HTTPException(status_code=400, detail=\"Failed to fetch repositories\")\n            \n        repos = response.json()\n        \n        # Connect to database to fetch additional details\n        try:\n            db_path = os.path.join(\"backend/database\", \"repos.db\")\n            with sqlite3.connect(db_path) as db:\n                cursor = db.cursor()\n                \n                result = []\n                for repo in repos:\n                    # Query database for each repository\n                    cursor.execute(\"SELECT is_active, backend_path FROM repos WHERE id = ?\", (repo[\"id\"],))\n                    db_data = cursor.fetchone()\n                    \n                    # Use database values if available, otherwise use defaults\n                    is_active = db_data[0] if db_data else False\n                    backend_path = db_data[1] if db_data else None\n                    \n                    result.append(\n                        Repository(\n                            id=repo[\"id\"],\n                            name=repo[\"name\"],\n                            full_name=repo[\"full_name\"],\n                            is_active=is_active,\n                            backend_path=backend_path\n                        )\n                    )\n                return result\n                \n        except sqlite3.Error as e:\n            logging.error(f\"Database error while fetching repository details: {e}\")\n            raise HTTPException(status_code=500, detail=\"Database error occurred\")\n        except Exception as e:\n            logging.error(f\"Unexpected error while processing repositories: {e}\")\n            raise HTTPException(status_code=500, detail=\"An unexpected error occurred\")\n    \n@router.get(\"/{repo_id}\")\nasync def get_repository_details(repo_id: int, current_user: dict = Depends(get_current_user)):\n    \"\"\"Get detailed information about a specific repository\"\"\"\n    async with httpx.AsyncClient() as client:\n        # Get repo details\n        response = await client.get(\n            f\"https://api.github.com/repositories/{repo_id}\",\n            headers={\n                \"Authorization\": f\"Bearer {current_user['github_token']}\",\n                \"Accept\": \"application/json\",\n            },\n        )\n        \n        if response.status_code != 200:\n            raise HTTPException(status_code=404, detail=\"Repository not found\")\n            \n        repo_data = response.json()\n        \n        # Get repository contents\n        contents_response = await client.get(\n            f\"https://api.github.com/repos/{repo_data['full_name']}/contents\",\n            headers={\n                \"Authorization\": f\"Bearer {current_user['github_token']}\",\n                \"Accept\": \"application/json\",\n            },\n        )\n        \n        if contents_response.status_code != 200:\n            raise HTTPException(status_code=400, detail=\"Failed to fetch repository contents\")\n            \n        contents = contents_response.json()\n        \n        # Extract directory structure\n        async def get_directory_contents(path=\"\"):\n            dir_response = await client.get(\n                f\"https://api.github.com/repos/{repo_data['full_name']}/contents/{path}\",\n                headers={\n                    \"Authorization\": f\"Bearer {current_user['github_token']}\",\n                    \"Accept\": \"application/json\",\n                },\n            )\n            \n            if dir_response.status_code != 200:\n                return []\n                \n            items = dir_response.json()\n            structure = []\n            \n            for item in items:\n                if item[\"type\"] == \"dir\":\n                    children = await get_directory_contents(item[\"path\"])\n                    structure.append({\n                        \"name\": item[\"name\"],\n                        \"path\": item[\"path\"],\n                        \"type\": \"directory\",\n                        \"children\": children\n                    })\n                else:\n                    structure.append({\n                        \"name\": item[\"name\"],\n                        \"path\": item[\"path\"],\n                        \"type\": \"file\"\n                    })\n                    \n            return structure\n\n        directory_structure = await get_directory_contents()\n        \n        return {\n            \"id\": repo_data[\"id\"],\n            \"name\": repo_data[\"name\"],\n            \"full_name\": repo_data[\"full_name\"],\n            \"default_branch\": repo_data[\"default_branch\"],\n            \"visibility\": repo_data[\"private\"] and \"private\" or \"public\",\n            \"directory_structure\": directory_structure\n        }\n\n@router.post(\"/read_docs\")\nasync def read_documentation(request: ReadDocsRequest):\n    try:\n        # Decode JWT to get GitHub token\n        try:\n            decoded_token = jwt.decode(request.access_token, options={\"verify_signature\": False})\n            github_token = decoded_token.get('github_token')\n            if not github_token:\n                return {\"Message\": \"GitHub token not found in JWT\"}\n        except jwt.InvalidTokenError:\n            return {\"Message\": \"Invalid JWT token\"}\n\n        async with httpx.AsyncClient() as client:\n            url = f\"https://api.github.com/repos/{request.full_name}/contents/documentation.yaml?ref=doccie\"\n            \n            headers = {\n                \"Authorization\": f\"Bearer {github_token}\",  # Changed from 'token' to 'Bearer'\n                \"Accept\": \"application/vnd.github.v3.raw\",\n                \"X-GitHub-Api-Version\": \"2022-11-28\"  # Added API version\n            }\n            \n            response = await client.get(url, headers=headers)\n            \n            if response.status_code == 401:\n                return {\n                    \"Message\": \"GitHub authentication failed. Please check your token.\",\n                    \"details\": response.text\n                }\n            \n            if response.status_code == 404:\n                return {\"Message\": \"Documentation file not found in doccie branch\"}\n            \n            if response.status_code != 200:\n                return {\n                    \"Message\": \"Failed to fetch documentation file\",\n                    \"status_code\": response.status_code,\n                    \"response\": response.text,\n                    \"url\": url\n                }\n                \n            try:\n                yaml_content = yaml.safe_load(response.text)\n            except yaml.YAMLError as e:\n                return {\"Message\": f\"Invalid YAML format: {str(e)}\"}\n                \n            return {\n                \"Message\": \"Documentation fetched successfully\",\n                \"data\": yaml_content\n            }\n            \n    except httpx.RequestError as e:\n        raise HTTPException(status_code=500, detail=f\"Request failed: {str(e)}\")\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Unexpected error: {str(e)}\")",
    "file_type": "server"
  },
  "backend/utils/auth.py": {
    "content": "from fastapi import Depends, HTTPException, status\nfrom fastapi.security import OAuth2PasswordBearer\nimport jwt\nimport os \nfrom dotenv import load_dotenv\nload_dotenv()\n\noauth2_scheme = OAuth2PasswordBearer(tokenUrl=\"token\")\n\nasync def get_current_user(token: str = Depends(oauth2_scheme)):\n    \"\"\"\n    Validate JWT token and return user info\n    \"\"\"\n    credentials_exception = HTTPException(\n        status_code=status.HTTP_401_UNAUTHORIZED,\n        detail=\"Could not validate credentials\",\n        headers={\"WWW-Authenticate\": \"Bearer\"},\n    )\n    \n    try:\n        # Decode JWT token\n        payload = jwt.decode(\n            token, \n            os.getenv(\"JWT_SECRET_KEY\"), \n            algorithms=os.getenv(\"JWT_ALGORITHM\")\n        )\n        \n        # Extract user data from payload\n        user_data = {\n            \"github_token\": payload.get(\"github_token\"),\n            \"user_id\": payload.get(\"user_id\"),\n            \"username\": payload.get(\"username\")\n        }\n        \n        if not all(user_data.values()):\n            raise credentials_exception\n            \n        return user_data\n        \n    except jwt.PyJWTError:\n        raise credentials_exception",
    "file_type": "server"
  },
  "client/eslint.config.js": {
    "content": "import js from '@eslint/js'\nimport globals from 'globals'\nimport react from 'eslint-plugin-react'\nimport reactHooks from 'eslint-plugin-react-hooks'\nimport reactRefresh from 'eslint-plugin-react-refresh'\n\nexport default [\n  { ignores: ['dist'] },\n  {\n    files: ['**/*.{js,jsx}'],\n    languageOptions: {\n      ecmaVersion: 2020,\n      globals: globals.browser,\n      parserOptions: {\n        ecmaVersion: 'latest',\n        ecmaFeatures: { jsx: true },\n        sourceType: 'module',\n      },\n    },\n    settings: { react: { version: '18.3' } },\n    plugins: {\n      react,\n      'react-hooks': reactHooks,\n      'react-refresh': reactRefresh,\n    },\n    rules: {\n      ...js.configs.recommended.rules,\n      ...react.configs.recommended.rules,\n      ...react.configs['jsx-runtime'].rules,\n      ...reactHooks.configs.recommended.rules,\n      'react/jsx-no-target-blank': 'off',\n      'react-refresh/only-export-components': [\n        'warn',\n        { allowConstantExport: true },\n      ],\n    },\n  },\n]\n",
    "file_type": "server"
  },
  "client/postcss.config.js": {
    "content": "export default {\n  plugins: {\n    tailwindcss: {},\n    autoprefixer: {},\n  },\n}\n",
    "file_type": "server"
  },
  "client/tailwind.config.js": {
    "content": "/** @type {import('tailwindcss').Config} */\nexport default {\n  content: [\n    \"./index.html\",\n    \"./src/**/*.{js,ts,jsx,tsx}\",\n  ],\n  theme: {\n    extend: {},\n  },\n  plugins: [],\n}",
    "file_type": "server"
  },
  "client/vite.config.js": {
    "content": "import { defineConfig } from 'vite'\nimport react from '@vitejs/plugin-react'\n\n// https://vite.dev/config/\nexport default defineConfig({\n  server: {\n    port: 3000, // or any other port you prefer\n  },\n  plugins: [react()],\n})\n",
    "file_type": "server"
  },
  "tester.py": {
    "content": "from dataclasses import dataclass\nfrom typing import Dict, List, Optional, Set, Tuple\nimport os\nimport ast\nimport re\nfrom pathlib import Path\nimport logging\nfrom functools import lru_cache\nimport hashlib\n\n@dataclass\nclass RouteInfo:\n    path: str\n    methods: List[str]\n    file_path: str\n    line_number: int\n    function_name: str\n    parameters: List[Dict[str, str]]\n    docstring: str\n    framework: str\n    response_type: Optional[str] = None\n    \n    def get_unique_id(self) -> str:\n        \"\"\"Generate unique identifier for route to prevent duplicates\"\"\"\n        content = f\"{self.path}:{':'.join(sorted(self.methods))}:{self.function_name}\"\n        return hashlib.md5(content.encode()).hexdigest()\n\nclass FrameworkDetector:\n    def __init__(self):\n        self.framework_patterns = {\n            'flask': {\n                'imports': [r'from\\s+flask\\s+import', r'import\\s+flask'],\n                'patterns': [r'@\\w+\\.route', r'Flask\\(__name__\\)'],\n            },\n            'fastapi': {\n                'imports': [r'from\\s+fastapi\\s+import', r'import\\s+fastapi'],\n                'patterns': [r'@\\w+\\.(get|post|put|delete|patch)', r'FastAPI\\(\\)'],\n            },\n            'django': {\n                'imports': [r'from\\s+django', r'import\\s+django'],\n                'patterns': [r'urlpatterns', r'path\\('],\n            },\n            'express': {\n                'imports': [r'express\\s*=\\s*require\\(\\'express\\'\\)', r'import\\s+express'],\n                'patterns': [r'app\\.(get|post|put|delete|patch)', r'router\\.(get|post|put|delete|patch)'],\n            }\n        }\n\n    @lru_cache(maxsize=1000)\n    def detect(self, content: str) -> str:\n        for framework, patterns in self.framework_patterns.items():\n            if any(re.search(p, content) for p in patterns['imports'] + patterns['patterns']):\n                return framework\n        return 'unknown'\n\nclass RouteParser:\n    def __init__(self):\n        self.framework_detector = FrameworkDetector()\n        self.logger = logging.getLogger(__name__)\n        self.seen_routes: Set[str] = set()\n        \n        self.route_patterns = {\n            'flask': [\n                (r'@\\w+\\.route\\([\\'\"](.+?)[\\'\"](,\\s*methods=\\[(.+?)\\])?\\)', self._parse_flask_route)\n            ],\n            'fastapi': [\n                (r'@\\w+\\.(get|post|put|delete|patch)\\([\\'\"](.+?)[\\'\"]\\)', self._parse_fastapi_route)\n            ],\n            'django': [\n                (r'path\\([\\'\"](.+?)[\\'\"]\\s*,\\s*\\w+\\.(\\w+)\\s*\\)', self._parse_django_route)\n            ],\n            'express': [\n                (r'\\w+\\.(get|post|put|delete|patch)\\([\\'\"](.+?)[\\'\"]\\)', self._parse_express_route)\n            ]\n        }\n\n    def parse_directory(self, directory: str, exclude_patterns: List[str] = None) -> List[RouteInfo]:\n        if exclude_patterns is None:\n            exclude_patterns = ['venv', 'node_modules', '__pycache__', '.git', 'tests']\n\n        all_routes = []\n        for root, dirs, files in os.walk(directory):\n            dirs[:] = [d for d in dirs if not any(pattern in d for pattern in exclude_patterns)]\n            \n            for file in files:\n                if file.endswith(('.py', '.js', '.ts')):\n                    file_path = os.path.join(root, file)\n                    try:\n                        routes = self.parse_file(file_path)\n                        all_routes.extend(routes)\n                    except Exception as e:\n                        self.logger.error(f\"Error parsing {file_path}: {str(e)}\")\n\n        return self._deduplicate_routes(all_routes)\n\n    def parse_file(self, file_path: str) -> List[RouteInfo]:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            content = f.read()\n\n        framework = self.framework_detector.detect(content)\n        if framework == 'unknown':\n            return []\n\n        routes = []\n        for pattern, parser in self.route_patterns.get(framework, []):\n            for match in re.finditer(pattern, content):\n                try:\n                    route_info = parser(match, file_path, content)\n                    if route_info:\n                        routes.append(route_info)\n                except Exception as e:\n                    self.logger.error(f\"Error parsing route in {file_path}: {str(e)}\")\n\n        return routes\n\n    def _deduplicate_routes(self, routes: List[RouteInfo]) -> List[RouteInfo]:\n        unique_routes = {}\n        for route in routes:\n            route_id = route.get_unique_id()\n            if route_id not in unique_routes:\n                unique_routes[route_id] = route\n            else:\n                # If duplicate found, keep the one with more complete information\n                existing_route = unique_routes[route_id]\n                if len(route.parameters) > len(existing_route.parameters) or len(route.docstring) > len(existing_route.docstring):\n                    unique_routes[route_id] = route\n        \n        return list(unique_routes.values())\n\n    def _get_line_number(self, content: str, match: re.Match) -> int:\n        return content.count('\\n', 0, match.start()) + 1\n\n    def _extract_function_info(self, content: str, match: re.Match) -> Tuple[str, List[Dict[str, str]], str]:\n        def parse_parameters(params_str: str) -> List[Dict[str, str]]:\n            params = []\n            for param in params_str.split(','):\n                param = param.strip()\n                if param:\n                    param_parts = param.split(':')\n                    param_name = param_parts[0].strip()\n                    param_type = param_parts[1].strip() if len(param_parts) > 1 else 'any'\n                    params.append({\n                        'name': param_name,\n                        'type': param_type,\n                        'required': not param_name.startswith('*')\n                    })\n            return params\n\n        function_pattern = r'def\\s+(\\w+)\\s*\\((.*?)\\)(?:\\s*->\\s*([^:]+))?:'\n        start_pos = match.end()\n        function_match = re.search(function_pattern, content[start_pos:])\n        \n        if not function_match:\n            return '', [], ''\n\n        function_name = function_match.group(1)\n        params_str = function_match.group(2)\n        return_type = function_match.group(3) if function_match.group(3) else None\n        parameters = parse_parameters(params_str)\n        \n        # Extract docstring\n        docstring = self._extract_docstring(content[start_pos + function_match.end():])\n        \n        return function_name, parameters, docstring\n\n    def _extract_docstring(self, content: str) -> str:\n        docstring_pattern = r'\"\"\"((?:.|\\n)*?)\"\"\"|\\'\\'\\'((?:.|\\n)*?)\\'\\'\\''\n        match = re.search(docstring_pattern, content)\n        if match:\n            return (match.group(1) or match.group(2)).strip()\n        return ''\n\n    def _parse_flask_route(self, match: re.Match, file_path: str, content: str) -> Optional[RouteInfo]:\n        path = match.group(1)\n        methods = [m.strip(' \\'\\\"') for m in match.group(3).split(',')] if match.group(3) else ['GET']\n        function_name, parameters, docstring = self._extract_function_info(content, match)\n        \n        return RouteInfo(\n            path=path,\n            methods=methods,\n            file_path=file_path,\n            line_number=self._get_line_number(content, match),\n            function_name=function_name,\n            parameters=parameters,\n            docstring=docstring,\n            framework='flask'\n        )\n\n    def _parse_fastapi_route(self, match: re.Match, file_path: str, content: str) -> Optional[RouteInfo]:\n        method = match.group(1).upper()\n        path = match.group(2)\n        function_name, parameters, docstring = self._extract_function_info(content, match)\n        \n        return RouteInfo(\n            path=path,\n            methods=[method],\n            file_path=file_path,\n            line_number=self._get_line_number(content, match),\n            function_name=function_name,\n            parameters=parameters,\n            docstring=docstring,\n            framework='fastapi'\n        )\n\n    def _parse_django_route(self, match: re.Match, file_path: str, content: str) -> Optional[RouteInfo]:\n        path = match.group(1)\n        view_name = match.group(2)\n        function_name, parameters, docstring = self._extract_function_info(content, match)\n        \n        return RouteInfo(\n            path=path,\n            methods=['GET'],  # Default to GET, actual methods should be extracted from view\n            file_path=file_path,\n            line_number=self._get_line_number(content, match),\n            function_name=function_name or view_name,\n            parameters=parameters,\n            docstring=docstring,\n            framework='django'\n        )\n\n    def _parse_express_route(self, match: re.Match, file_path: str, content: str) -> Optional[RouteInfo]:\n        method = match.group(1).upper()\n        path = match.group(2)\n        function_name, parameters, docstring = self._extract_function_info(content, match)\n        \n        return RouteInfo(\n            path=path,\n            methods=[method],\n            file_path=file_path,\n            line_number=self._get_line_number(content, match),\n            function_name=function_name,\n            parameters=parameters,\n            docstring=docstring,\n            framework='express'\n        )\n\nclass APIParser:\n    def __init__(self):\n        self.route_parser = RouteParser()\n        self.logger = logging.getLogger(__name__)\n\n    def parse(self, directory: str) -> List[Dict]:\n        \"\"\"Main entry point for parsing API routes\"\"\"\n        routes = self.route_parser.parse_directory(directory)\n        return [self._route_to_dict(route) for route in routes]\n\n    def _route_to_dict(self, route: RouteInfo) -> Dict:\n        \"\"\"Convert RouteInfo to dictionary format\"\"\"\n        return {\n            'path': route.path,\n            'methods': route.methods,\n            'location': {\n                'file': route.file_path,\n                'line': route.line_number\n            },\n            'handler': {\n                'name': route.function_name,\n                'parameters': route.parameters,\n                'docstring': route.docstring,\n                'response_type': route.response_type\n            },\n            'framework': route.framework,\n            'unique_id': route.get_unique_id()\n        }\n    \nparser = APIParser()\nroutes = parser.parse(directory=\"./backend/\")\n\nfrom rich.pretty import pprint\npprint(routes)",
    "file_type": "server"
  }
}